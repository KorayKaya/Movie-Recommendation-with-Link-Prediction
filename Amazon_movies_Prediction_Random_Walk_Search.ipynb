{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QUR_8TxjwT6c"
   },
   "outputs": [],
   "source": [
    "import Graph_Amazon_Movies as gam\n",
    "import Amazon_Movie_Parser as amp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from networkx.algorithms import bipartite\n",
    "import networkx as nx\n",
    "import Amazon_Movie_Parser as prs\n",
    "import datetime\n",
    "from numpy import savetxt\n",
    "import Computations_debug as comp\n",
    "import random\n",
    "\n",
    "#import Predict_Movie as pm\n",
    "import Predict_Movie_v1 as pm\n",
    "#import Predict_Movie_v2 as pm\n",
    "#import Predict_Movie_v3 as pm\n",
    "#import Predict_Movie_v4 as pm\n",
    "pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you run this in colab *** it has a very limited RAM 12GB if I'm not mistaken, so works for 20K not 40K\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_amazon = pm.Amazon()\n",
    "#predict_amazon.debug_mode = 'On'\n",
    "#predict_amazon.file_type = 'pickle'\n",
    "# **** we need to filter out the movies the person has already reviewed previously ****\n",
    "# because the same movie can appear in the test data-set since some new users might review it this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_movies = 50000 .. n_movies_v = 20500 .. n_test_users = 100\n",
      "walk_steps = 40 .. top_neighbor = 50\n",
      "----------------------------------------------\n",
      "Calculation starts for above values: 2020-05-30 10:32:06.478843\n",
      "*************** 1st Graph calculations - MODEL *************** \n",
      "Calculation time-Crete graph from the movies file: 0:01:02.129712\n",
      "Is connected: True ... Is bipartite: True\n",
      "# of nodes: 35940 ... # of edges: 47984\n",
      "Calculation time-1st Part: 0:01:03.829501\n",
      "\n",
      "*************** 2nd Graph calculations - TEST *************** \n",
      "Create_Bipartite_VALIDATION is running...\n",
      "Calculation time-Crete graph from the movies file: 0:00:09.143592\n",
      "Is connected: True ... Is bipartite: True\n",
      "# of nodes: 15829 ... # of edges: 19293\n",
      "n_movies for modeling (P matrix) = 1019 .. n_movies for testing = 357\n",
      "n_users for modeling (P matrix) = 34921 .. n_users for testing = 15472\n",
      "Avg degree (edge) per user in MODELING GRAPH: 1.3740729074196043  ... in TEST GRAPH: 1.2469622543950363\n",
      "Calculation time-2nd Part: 0:00:10.208031\n",
      "**********************************************\n",
      "Calculation time for ALL-Part-1: 0:01:14.039912\n",
      "Preparation starts at 2020-05-30 10:33:20.519004\n",
      "P to_numpy_matrix: 2020-05-30 10:33:21.526912\n",
      "P normalize: 2020-05-30 10:33:38.912175\n",
      "P finalize: 2020-05-30 10:33:46.982360\n",
      "Calculation time-P matrix generation from the graph: 0:00:25.455436\n",
      "P_norm is generated: 2020-05-30 10:33:47.651447\n",
      "Calculation time-user-movie indexes: 0:00:29.960432\n",
      "\n",
      "\n",
      "Calculation time-user-movie indexes: 0:00:03.289906\n",
      "\n",
      "\n",
      "FOR loop starts in top-K users: 2020-05-30 10:34:21.058236\n",
      "0. of 100 Random walk starts for 21703-AGKJF15QQNVX6 at 2020-05-30 10:34:21.060526\n",
      "Calculate the ratios per movie: 0\n",
      "10. of 100 Random walk starts for 6227-A3KVRUF6OD80FO at 2020-05-30 10:40:05.225939\n",
      "Calculate the ratios per movie: 10\n",
      "20. of 100 Random walk starts for 8365-A3TK2IOP8UQ087 at 2020-05-30 10:45:55.928743\n",
      "Calculate the ratios per movie: 20\n",
      "30. of 100 Random walk starts for 14664-ACR1OJGNVVRE1 at 2020-05-30 10:51:35.318889\n",
      "Calculate the ratios per movie: 30\n",
      "40. of 100 Random walk starts for 6182-A1ERD893AWOD5B at 2020-05-30 10:57:25.411088\n",
      "Calculate the ratios per movie: 40\n",
      "50. of 100 Random walk starts for 570-AY6QWTWG99N2B at 2020-05-30 11:03:16.772509\n",
      "Calculate the ratios per movie: 50\n",
      "60. of 100 Random walk starts for 5414-A3SQ1PMWIP8MXW at 2020-05-30 11:09:17.741364\n",
      "Calculate the ratios per movie: 60\n",
      "70. of 100 Random walk starts for 5547-A2NX99GVAX4TRP at 2020-05-30 11:15:04.722893\n",
      "Calculate the ratios per movie: 70\n",
      "80. of 100 Random walk starts for 7281-A2CZPM110DW516 at 2020-05-30 11:20:47.418841\n",
      "Calculate the ratios per movie: 80\n",
      "90. of 100 Random walk starts for 9311-A1CQON0P01BITL at 2020-05-30 11:26:28.616432\n",
      "Calculate the ratios per movie: 90\n",
      "99. of 100 Random walk starts for 1899-ABLOQZIL42W7I at 2020-05-30 11:31:44.776199\n",
      "Calculate the ratios per movie: 99\n",
      "MOVIES >> YES: Exist in both .. NO: Exist in dataset-2 but not exist in dataset-1\n",
      "count_YES: 0 .. count_NO: 357\n",
      "USERS >> YES: Exist in both .. NO: Exist in dataset-2 but not exist in dataset-1\n",
      "count_YES: 3834 .. count_NO: 11638\n",
      "MOVIES >> YES: Exist in both .. NO: Exist in dataset-1 but not exist in dataset-2\n",
      "count_YES: 0 .. count_NO: 1019\n",
      "USERS >> YES: Exist in both .. NO: Exist in dataset-1 but not exist in dataset-2\n",
      "count_YES: 3834 .. count_NO: 31087\n",
      "**********************************************\n",
      "Calculation time for run_validation_TOP_N: 0:58:58.315908\n",
      "Performance Values are saved in RESULTS/PerformanceValues_0.9258_30.5.2020_11.32.20.csv\n",
      "Performance Values are saved in RESULTS/PerformanceValues_ALL_0.7942_30.5.2020_11.42.41.csv\n",
      "Prediction Details are saved in RESULTS/PredictionDetails_50000_20500_100_40_50_TOP1_30.5.2020_11.42.41.csv\n",
      "Prediction_all Details are saved in RESULTS/PredictionDetails_ALL_50000_20500_100_40_50_TOP1_30.5.2020_11.42.41.csv\n",
      "Calculation time for ALL-Predictions: 2020-05-30 11:42:41.368779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n>>>> df_FINAL (PredictionDetails.csv file)\\n> prediction: our prediction whether or not the given user will review the given movie on the list or not \\ndepending on the given threshold\\n> reality: \\n> threshold: if ngbr_ratio > threshold then prediction=1 else 0\\n> ngbr_ratio: how many percent of your top-K similar users reviewed this movie\\n> tot_rev_m: how many times was this movie reviewed \\n> n_old_edge: how many times did this user make a review in the old dataset\\n> n_new_edge: how many times did this user make a review in the new dataset\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = 'data/movies.txt'; n_movies = 50000; n_movies_v = 20500; n_test_users = 100; walk_steps = 40\n",
    "start_index_v = n_movies; beta = 0.1; top_neighbor = 50; top_N_movie_suggestions = 1\n",
    "\n",
    "#file_name = 'data/movies.txt'; n_movies = 2000; n_movies_v = 2000; n_test_users = 40; walk_steps = 30\n",
    "#start_index_v = n_movies; beta = 0.15; top_neighbor = 50\n",
    "\n",
    "#lst_n_movies_test = [20000, 30000, 40000, 50000]\n",
    "#lst_n_movies_test_v = [10000, 11000, 12000, 13000, 14000]\n",
    "#lst_n_movies_test_v = [2000, 4000, 6000, 8000]\n",
    "lst_n_movies_test_v = [20500]\n",
    "\n",
    "start_time_ALL = datetime.datetime.now()\n",
    "#for n_movies in lst_n_movies_test:\n",
    "for n_movies_v in lst_n_movies_test_v:\n",
    "    start_index_v = n_movies\n",
    "    start_time_part1 = datetime.datetime.now()\n",
    "\n",
    "    print('\\nn_movies = {} .. n_movies_v = {} .. n_test_users = {}'.format(n_movies, n_movies_v, n_test_users))\n",
    "    print('walk_steps = {} .. top_neighbor = {}'.format(walk_steps, top_neighbor))\n",
    "    print('----------------------------------------------')\n",
    "    print('Calculation starts for above values: {}'.format(start_time_part1))\n",
    "\n",
    "    max_connected_gr_amazon_movies, max_connected_gr_amazon_movies_VAL = \\\n",
    "    predict_amazon.create_graphs(file_name, n_movies, n_movies_v, start_index_v)\n",
    "\n",
    "    end_time_part1 = datetime.datetime.now()\n",
    "    total_time_part1 = end_time_part1 - start_time_part1\n",
    "    print('**********************************************')\n",
    "    print('Calculation time for ALL-Part-1: {}'.format(total_time_part1))\n",
    "    \n",
    "    start_time_part2 = datetime.datetime.now()\n",
    "\n",
    "    '''\n",
    "    df_FINAL = \\\n",
    "    predict_amazon.run_validation(max_connected_gr_amazon_movies, max_connected_gr_amazon_movies_VAL,\\\n",
    "                                  walk_steps, n_test_users, beta, top_neighbor)\n",
    "    '''\n",
    "    '''\n",
    "    df_FINAL = \\\n",
    "    predict_amazon.run_validation_TOP_N(max_connected_gr_amazon_movies, max_connected_gr_amazon_movies_VAL,\\\n",
    "                                  walk_steps, n_test_users, beta, top_neighbor, top_N_movie_suggestions)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    df_FINAL, df_FINAL_all = \\\n",
    "    predict_amazon.run_validation_TOP_N(max_connected_gr_amazon_movies, max_connected_gr_amazon_movies_VAL,\\\n",
    "                                  walk_steps, n_test_users, beta, top_neighbor, top_N_movie_suggestions)\n",
    "\n",
    "    end_time_part2 = datetime.datetime.now()\n",
    "    total_time_part2 = end_time_part2 - start_time_part2\n",
    "    \n",
    "    #start_time_part3 = datetime.datetime.now()\n",
    "    # df_perf is saved in a csv, too, but it i done in the function \"save_performance_values\"\n",
    "    df_perf = predict_amazon.save_performance_values(df_FINAL, total_time_part1, total_time_part2)\n",
    "    \n",
    "    df_perf_all = predict_amazon.save_performance_values_ALL(df_FINAL_all, total_time_part1, total_time_part2)\n",
    "    #end_time_part3 = datetime.datetime.now()\n",
    "    #total_time_part3 = end_time_part3 - start_time_part3\n",
    "\n",
    "    # just to avoid failure if there is no RESULTS directory\n",
    "    try:\n",
    "        file_prefix = \"RESULTS/PredictionDetails_\" + str(n_movies) + \"_\" + str(n_movies_v) + \"_\" + \\\n",
    "        str(n_test_users) + \"_\" + str(walk_steps) + \"_\" + str(top_neighbor) + \\\n",
    "        \"_TOP\" + str(top_N_movie_suggestions) + \"_\"\n",
    "        \n",
    "        file_prefix_all = \"RESULTS/PredictionDetails_ALL_\" + str(n_movies) + \"_\" + str(n_movies_v) + \"_\" + \\\n",
    "        str(n_test_users) + \"_\" + str(walk_steps) + \"_\" + str(top_neighbor) + \\\n",
    "        \"_TOP\" + str(top_N_movie_suggestions) + \"_\"\n",
    "    except:\n",
    "        file_prefix = \"PredictionDetails_\" + str(n_movies) + \"_\" + str(n_movies_v) + \"_\" + \\\n",
    "        str(n_test_users) + \"_\" + str(walk_steps) + \"_\" + str(top_neighbor) + \\\n",
    "        \"_TOP\" + str(top_N_movie_suggestions) + \"_\"\n",
    "        \n",
    "        file_prefix_all = \"PredictionDetails_ALL_\" + str(n_movies) + \"_\" + str(n_movies_v) + \"_\" + \\\n",
    "        str(n_test_users) + \"_\" + str(walk_steps) + \"_\" + str(top_neighbor) + \\\n",
    "        \"_TOP\" + str(top_N_movie_suggestions) + \"_\"\n",
    "                                                \n",
    "    #fileName_Details = prs.FileNameUnique(prefix = \"RESULTS/PredictionDetails_\", suffix = '.csv')\n",
    "    fileName_Details = prs.FileNameUnique(prefix = file_prefix, suffix = '.csv')\n",
    "    fileName_Details_all = prs.FileNameUnique(prefix = file_prefix_all, suffix = '.csv')\n",
    "    \n",
    "    df_FINAL.to_csv(fileName_Details)\n",
    "    df_FINAL_all.to_csv(fileName_Details_all)\n",
    "    print('Prediction Details are saved in {}'.format(fileName_Details))\n",
    "    print('Prediction_all Details are saved in {}'.format(fileName_Details_all))\n",
    "    df_perf\n",
    "\n",
    "end_time_ALL = datetime.datetime.now()\n",
    "print('Calculation time for ALL-Predictions: {}'.format(end_time_ALL))\n",
    "\n",
    "# it is taking SOOOOOO LONG time, had to stop it (even for 12K edges). Let's try in smaller networks later..\n",
    "#d_model = nx.diameter(max_connected_gr_amazon_movies)\n",
    "#d_test = nx.diameter(max_connected_gr_amazon_movies)\n",
    "\n",
    "#print('Diameter of MODEL: {}\\tTEST: {}'.format(d_model, d_test))\n",
    "\n",
    "'''\n",
    ">>>> df_FINAL (PredictionDetails.csv file)\n",
    "> prediction: our prediction whether or not the given user will review the given movie on the list or not \n",
    "depending on the given threshold\n",
    "> reality: \n",
    "> threshold: if ngbr_ratio > threshold then prediction=1 else 0\n",
    "> ngbr_ratio: how many percent of your top-K similar users reviewed this movie\n",
    "> tot_rev_m: how many times was this movie reviewed \n",
    "> n_old_edge: how many times did this user make a review in the old dataset\n",
    "> n_new_edge: how many times did this user make a review in the new dataset\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>TPR</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Thresholds</th>\n",
       "      <th>Calc_Time</th>\n",
       "      <th>lst_name</th>\n",
       "      <th>lst_value</th>\n",
       "      <th>other_metrics</th>\n",
       "      <th>metrics_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.925781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>Graph Creation</td>\n",
       "      <td>debug_mode</td>\n",
       "      <td>Off</td>\n",
       "      <td>threshold</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0:01:14.039912</td>\n",
       "      <td>n_movies_model</td>\n",
       "      <td>50000</td>\n",
       "      <td>acc</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0.805556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Random Walk &amp; Prediction</td>\n",
       "      <td>n_movies_validation</td>\n",
       "      <td>20500</td>\n",
       "      <td>tpr</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>0.805556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>30</td>\n",
       "      <td>0:58:59.146140</td>\n",
       "      <td>walk_steps</td>\n",
       "      <td>40</td>\n",
       "      <td>fpr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>28</td>\n",
       "      <td>Threshold search</td>\n",
       "      <td>beta</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tnr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>26</td>\n",
       "      <td>0:00:00.719546</td>\n",
       "      <td>top_neighbor</td>\n",
       "      <td>50</td>\n",
       "      <td>fnr</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>24</td>\n",
       "      <td>TOTAL TIME</td>\n",
       "      <td>n_test_users</td>\n",
       "      <td>100</td>\n",
       "      <td>precision</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>22</td>\n",
       "      <td>1:00:13.905598</td>\n",
       "      <td>threshold</td>\n",
       "      <td>40</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>20</td>\n",
       "      <td></td>\n",
       "      <td>start_index_v</td>\n",
       "      <td>50000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>18</td>\n",
       "      <td></td>\n",
       "      <td>file_name</td>\n",
       "      <td>data/movies.txt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.375</td>\n",
       "      <td>16</td>\n",
       "      <td></td>\n",
       "      <td>top_N_suggestions</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td></td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.443038</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>0.875</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td></td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>decision_4</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.360000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           AUC       TPR  Precision       FPR Thresholds  \\\n",
       "0   0.925781    0.000000  0.000000   0         101         \n",
       "1               0.722222  0.000000   0         100         \n",
       "2               0.805556  1.000000   0         40          \n",
       "3               0.805556  1.000000   0.015625  30          \n",
       "4               0.833333  0.966667   0.046875  28          \n",
       "5               0.833333  0.909091   0.109375  26          \n",
       "6               0.861111  0.810811   0.140625  24          \n",
       "7               0.861111  0.775000   0.1875    22          \n",
       "8               0.888889  0.720930   0.3125    20          \n",
       "9               0.888889  0.615385   0.359375  18          \n",
       "10              0.888889  0.581818   0.375     16          \n",
       "11              0.916667  0.571429   0.4375    14          \n",
       "12              0.972222  0.485714   0.6875    10          \n",
       "13              1.000000  0.443038   0.78125   8           \n",
       "14              1.000000  0.418605   0.875     6           \n",
       "15              1.000000  0.391304   0.984375  4           \n",
       "16              1.000000  0.363636   1         2           \n",
       "17  decision_4  0.236842  0.360000                         \n",
       "\n",
       "                   Calc_Time             lst_name        lst_value  \\\n",
       "0   Graph Creation            debug_mode           Off               \n",
       "1   0:01:14.039912            n_movies_model       50000             \n",
       "2   Random Walk & Prediction  n_movies_validation  20500             \n",
       "3   0:58:59.146140            walk_steps           40                \n",
       "4   Threshold search          beta                 0.1               \n",
       "5   0:00:00.719546            top_neighbor         50                \n",
       "6   TOTAL TIME                n_test_users         100               \n",
       "7   1:00:13.905598            threshold            40                \n",
       "8                             start_index_v        50000             \n",
       "9                             file_name            data/movies.txt   \n",
       "10                            top_N_suggestions    1                 \n",
       "11                                                                   \n",
       "12                                                                   \n",
       "13                                                                   \n",
       "14                                                                   \n",
       "15                                                                   \n",
       "16                                                                   \n",
       "17                                                                   \n",
       "\n",
       "   other_metrics metrics_val  \n",
       "0   threshold     40          \n",
       "1   acc           0.92        \n",
       "2   tpr           0.777778    \n",
       "3   fpr           0           \n",
       "4   tnr           1           \n",
       "5   fnr           0.222222    \n",
       "6   precision     1           \n",
       "7   f1            0.875       \n",
       "8                             \n",
       "9                             \n",
       "10                            \n",
       "11                            \n",
       "12                            \n",
       "13                            \n",
       "14                            \n",
       "15                            \n",
       "16                            \n",
       "17                            "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_df = predict_amazon.show_parameters_in_use()\n",
    "params_df.style.set_properties(**{'text-align': 'left'})\n",
    "\n",
    "df_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>TPR</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Thresholds</th>\n",
       "      <th>Calc_Time</th>\n",
       "      <th>lst_name</th>\n",
       "      <th>lst_value</th>\n",
       "      <th>other_metrics</th>\n",
       "      <th>metrics_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.794235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101.0</td>\n",
       "      <td>Graph Creation</td>\n",
       "      <td>debug_mode</td>\n",
       "      <td>Off</td>\n",
       "      <td>threshold</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0.171053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0:01:14.039912</td>\n",
       "      <td>n_movies_model</td>\n",
       "      <td>50000</td>\n",
       "      <td>acc</td>\n",
       "      <td>0.996527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0.190789</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Random Walk &amp; Prediction</td>\n",
       "      <td>n_movies_validation</td>\n",
       "      <td>20500</td>\n",
       "      <td>tpr</td>\n",
       "      <td>0.184211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>0.190789</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0:58:59.146140</td>\n",
       "      <td>walk_steps</td>\n",
       "      <td>40</td>\n",
       "      <td>fpr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>0.197368</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Threshold search</td>\n",
       "      <td>beta</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tnr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>0.197368</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0:10:20.577112</td>\n",
       "      <td>top_neighbor</td>\n",
       "      <td>50</td>\n",
       "      <td>fnr</td>\n",
       "      <td>0.815789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>24.0</td>\n",
       "      <td>TOTAL TIME</td>\n",
       "      <td>n_test_users</td>\n",
       "      <td>100</td>\n",
       "      <td>precision</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1:10:33.763164</td>\n",
       "      <td>threshold</td>\n",
       "      <td>40</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.311111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>0.217105</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>20.0</td>\n",
       "      <td></td>\n",
       "      <td>start_index_v</td>\n",
       "      <td>50000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td>0.243421</td>\n",
       "      <td>0.358696</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>18.0</td>\n",
       "      <td></td>\n",
       "      <td>file_name</td>\n",
       "      <td>data/movies.txt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td>0.256579</td>\n",
       "      <td>0.296000</td>\n",
       "      <td>0.003826</td>\n",
       "      <td>16.0</td>\n",
       "      <td></td>\n",
       "      <td>top_N_suggestions</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>0.269737</td>\n",
       "      <td>0.222857</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>14.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>0.309211</td>\n",
       "      <td>0.144366</td>\n",
       "      <td>0.010155</td>\n",
       "      <td>12.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td></td>\n",
       "      <td>0.348684</td>\n",
       "      <td>0.115196</td>\n",
       "      <td>0.015894</td>\n",
       "      <td>10.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.085761</td>\n",
       "      <td>0.027287</td>\n",
       "      <td>8.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td>0.486842</td>\n",
       "      <td>0.061896</td>\n",
       "      <td>0.049060</td>\n",
       "      <td>6.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td></td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.040704</td>\n",
       "      <td>0.093648</td>\n",
       "      <td>4.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td></td>\n",
       "      <td>0.723684</td>\n",
       "      <td>0.024612</td>\n",
       "      <td>0.222629</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td></td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013709</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AUC       TPR  Precision       FPR  Thresholds  \\\n",
       "0   0.794235  0.000000  0.000000   0.000000  101.0        \n",
       "1             0.171053  0.000000   0.000000  100.0        \n",
       "2             0.190789  1.000000   0.000000  40.0         \n",
       "3             0.190789  1.000000   0.000028  30.0         \n",
       "4             0.197368  0.966667   0.000113  28.0         \n",
       "5             0.197368  0.882353   0.000281  26.0         \n",
       "6             0.210526  0.750000   0.000647  24.0         \n",
       "7             0.210526  0.581818   0.000900  22.0         \n",
       "8             0.217105  0.500000   0.001660  20.0         \n",
       "9             0.243421  0.358696   0.002476  18.0         \n",
       "10            0.256579  0.296000   0.003826  16.0         \n",
       "11            0.269737  0.222857   0.006836  14.0         \n",
       "12            0.309211  0.144366   0.010155  12.0         \n",
       "13            0.348684  0.115196   0.015894  10.0         \n",
       "14            0.421053  0.085761   0.027287  8.0          \n",
       "15            0.486842  0.061896   0.049060  6.0          \n",
       "16            0.552632  0.040704   0.093648  4.0          \n",
       "17            0.723684  0.024612   0.222629  2.0          \n",
       "18            1.000000  0.013709   1.000000  0.0          \n",
       "\n",
       "                   Calc_Time             lst_name        lst_value  \\\n",
       "0   Graph Creation            debug_mode           Off               \n",
       "1   0:01:14.039912            n_movies_model       50000             \n",
       "2   Random Walk & Prediction  n_movies_validation  20500             \n",
       "3   0:58:59.146140            walk_steps           40                \n",
       "4   Threshold search          beta                 0.1               \n",
       "5   0:10:20.577112            top_neighbor         50                \n",
       "6   TOTAL TIME                n_test_users         100               \n",
       "7   1:10:33.763164            threshold            40                \n",
       "8                             start_index_v        50000             \n",
       "9                             file_name            data/movies.txt   \n",
       "10                            top_N_suggestions    1                 \n",
       "11                                                                   \n",
       "12                                                                   \n",
       "13                                                                   \n",
       "14                                                                   \n",
       "15                                                                   \n",
       "16                                                                   \n",
       "17                                                                   \n",
       "18                                                                   \n",
       "\n",
       "   other_metrics metrics_val  \n",
       "0   threshold     40          \n",
       "1   acc           0.996527    \n",
       "2   tpr           0.184211    \n",
       "3   fpr           0           \n",
       "4   tnr           1           \n",
       "5   fnr           0.815789    \n",
       "6   precision     1           \n",
       "7   f1            0.311111    \n",
       "8                             \n",
       "9                             \n",
       "10                            \n",
       "11                            \n",
       "12                            \n",
       "13                            \n",
       "14                            \n",
       "15                            \n",
       "16                            \n",
       "17                            \n",
       "18                            "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_perf_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is taking SOOOOOO LONG time\n",
    "#d_model = nx.diameter(max_connected_gr_amazon_movies)\n",
    "#d_test = nx.diameter(max_connected_gr_amazon_movies_VAL)\n",
    "#print('Diameter of MODEL: {}\\tTEST: {}'.format(d_model, d_test))\n",
    "\n",
    "# centrality is fast\n",
    "#centrality = nx.eigenvector_centrality_numpy(max_connected_gr_amazon_movies_VAL)\n",
    "#print(centrality)\n",
    "\n",
    "# if we use a small k, it doesn't take much time\n",
    "#bc = nx.betweenness_centrality(max_connected_gr_amazon_movies_VAL, k=100)\n",
    "#print(bc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(max_connected_gr_amazon_movies.edges('A1N0LCPR7O7OLL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'betweenness_centrality' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-bc9d616931ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#closeness_centrality = bipartite.closeness_centrality(max_connected_gr_amazon_movies_VAL, top_nodes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#st.mean(list(degree_centrality.values()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbetweenness_centrality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#---- degree_centrality (normalized) = deg(v)/max_possible_edges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# bottom-nodes: avg normalized-degree_centrality: 0.003492891468893659=VAL  ....  0.001348452313463792\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'betweenness_centrality' is not defined"
     ]
    }
   ],
   "source": [
    "import statistics as st\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "\n",
    "bottom_nodes, top_nodes = bipartite.sets(max_connected_gr_amazon_movies_VAL)\n",
    "# top_nodes=movies   ...  bottom_nodes=users\n",
    "degree_centrality = bipartite.degree_centrality(max_connected_gr_amazon_movies_VAL, top_nodes)\n",
    "#betweenness_centrality = bipartite.betweenness_centrality(max_connected_gr_amazon_movies_VAL, top_nodes)\n",
    "#closeness_centrality = bipartite.closeness_centrality(max_connected_gr_amazon_movies_VAL, top_nodes)\n",
    "#st.mean(list(degree_centrality.values()))\n",
    "st.mean(list(betweenness_centrality.values()))\n",
    "#---- degree_centrality (normalized) = deg(v)/max_possible_edges\n",
    "# bottom-nodes: avg normalized-degree_centrality: 0.003492891468893659=VAL  ....  0.001348452313463792\n",
    "# top-nodes: avg normalized-degree_centrality:    0.003492891468893659=VAL  ....  0.001348452313463792\n",
    "#---- closeness_centrality\n",
    "#---- https://networkx.github.io/documentation/stable/reference/algorithms/generated/networkx.algorithms.bipartite.centrality.closeness_centrality.html#networkx.algorithms.bipartite.centrality.closeness_centrality\n",
    "# bottom-nodes: avg. closeness_centrality: ?=VAL                   ....  ?\n",
    "# top-nodes: avg. closeness_centrality:    0.3937692751347393=VAL  ....  ?\n",
    "#---- betweenness_centrality\n",
    "# even if select bottom or top nodes, it always gives the result for bottom_nodes=USERS\n",
    "# bottom-nodes: avg. betweenness_centrality: 1.2469622543950363=VAL  (just gave the avg. degree..)  ....  ?\n",
    "# top-nodes: avg. betweenness_centrality:    1.2469622543950363=VAL  ....  ?\n",
    "#----\n",
    "# degree distribution\n",
    "#degrees(B, nodes[, weight])\n",
    "# careful here.. if you pass top_nodes as an argument, \n",
    "# it returns the values for bottom_nodes as the first result and the top_nodes as the second result.. and vice versa\n",
    "#degree_distribution_Bottom, degree_distribution_TOP = bipartite.degrees(max_connected_gr_amazon_movies_VAL, top_nodes)\n",
    "#print(len(degree_distribution_TOP))\n",
    "#----\n",
    "#bipartite.color(max_connected_gr_amazon_movies_VAL)\n",
    "#----\n",
    "# returns the same for both bottom and top... same value with avg normalized-degree_centrality\n",
    "#dens_m = bipartite.density(max_connected_gr_amazon_movies_VAL, bottom_nodes)\n",
    "#print(dens_m)\n",
    "#---- clustering coeff for the whole graph\n",
    "#avg_cluster = bipartite.average_clustering(max_connected_gr_amazon_movies_VAL, bottom_nodes)\n",
    "#print(avg_cluster)\n",
    "# 1.2469622543950363 >> (just gave the avg. degree..)\n",
    "#----\n",
    "#n_redundancy = bipartite.node_redundancy(max_connected_gr_amazon_movies_VAL, bottom_nodes)\n",
    "#print(n_redundancy)\n",
    "# NetworkXError: Cannot compute redundancy coefficient for a node that has fewer than two neighbors.\n",
    "print('{} .. {}'.format(len(top_nodes), len(bottom_nodes)))\n",
    "357*0.003492891468893659\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_amazon.df_summary_ratio_v.query(\"movie=='B000N2HD7I'\").values[0].tolist()[1]\n",
    "pd.options.display.max_rows = 1000\n",
    "predict_amazon.df_summary_ratio_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes too much time to run, as well\n",
    "# The eccentricity of a node v is the maximum distance from v to all other nodes in G.\n",
    "# Returns: ecc â€“ A dictionary of eccentricity values keyed by node.\n",
    "# eccentricity(G, v=None, sp=None)\n",
    "#e_model = nx.eccentricity(max_connected_gr_amazon_movies)\n",
    "#e_test = nx.eccentricity(max_connected_gr_amazon_movies_VAL)\n",
    "\n",
    "#print('Eccentricity of MODEL: {}\\tTEST: {}'.format(e_model, e_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5ae0076c2146>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# below table shows the prediction for threshold>10% so don't pay attention to it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# also tot_rev_m_NEW & OLD will be double checked, seems like a bug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf_FINAL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# below table shows the prediction for threshold>10% so don't pay attention to it\n",
    "# also tot_rev_m_NEW & OLD will be double checked, seems like a bug\n",
    "pd.options.display.max_rows = 1000\n",
    "df_FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.options.display.max_rows = 35500\n",
    "df_FINAL_all.query(\"user=='A22GKUN35R09KN' and movie=='B000J6I0TS'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "total_reviews = 0\n",
    "        # total number of reviews that those 100 test users did in dataset-2\n",
    "        for u in df_FINAL['user'].unique():\n",
    "            n_movie_reviewed_new = df_FINAL.query(\"user == '\" + u + \"'\")['n_new_edge'][0]\n",
    "            total_reviews += n_movie_reviewed_new\n",
    "\n",
    "\n",
    "\n",
    "for u in df_FINAL['user'].unique():\n",
    "    print(u)\n",
    "    print(df_FINAL.query(\"user == '\" + u + \"'\")['n_new_edge'].values[0])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_FINAL['movie'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for t in thresholds:\n",
    "    acc, tpr, fpr, tnr, fnr, ppv, f1 = predict_amazon.final_summary_threshold_based(df_FINAL, t)\n",
    "    lst_t = [t,  acc, tpr, fpr, tnr, fnr, ppv, f1]\n",
    "    lst_presicion_based.append(lst_t)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df_FINAL_copy = df_FINAL.copy()\n",
    "\n",
    "threshold = 4\n",
    "for i in range(len(df_FINAL_copy)):\n",
    "    if df_FINAL_copy.loc[i, 'ngbr_ratio'] > threshold:\n",
    "        df_FINAL_copy.loc[i, 'prediction'] = 1\n",
    "    else:\n",
    "        df_FINAL_copy.loc[i, 'prediction'] = 0\n",
    "        \n",
    "acc, tpr, fpr, tnr, ppv, f1 = predict_amazon.final_summary(df_FINAL_copy)\n",
    "\n",
    "print(tpr)\n",
    "\n",
    "#p_recall = tpr / (tpr + fnr)\n",
    "#print(recall)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_true_val = df_FINAL.loc[:, 'reality'].values.tolist()\n",
    "lst_ratio_val = df_FINAL.loc[:, 'ngbr_ratio'].values.tolist()\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(lst_true_val, lst_ratio_val)  #, pos_label=2\n",
    "lst_tpr = list(tpr); lst_fpr = list(fpr); lst_thresholds = list(thresholds) \n",
    "\n",
    "print(tpr)\n",
    "print(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "y_true = df_FINAL.loc[:, 'reality'].values.tolist()\n",
    "y_pred = df_FINAL.loc[:, 'ngbr_ratio'].values.tolist()\n",
    "\n",
    "roc_auc = roc_auc_score(y_true, y_pred)\n",
    "print(roc_auc)\n",
    "\n",
    "#precision = precision_score(y_true, y_pred, average='macro') # 'micro'  'weighted' None  average=None, zero_division=1\n",
    "#print(precision)\n",
    "\n",
    "precision_recall = precision_recall_curve(y_true, y_pred)\n",
    "#print(list(precision_recall))\n",
    "\n",
    "avg_precision = average_precision_score(y_true, y_pred)\n",
    "#print(avg_precision)\n",
    "\n",
    "#lst_tpr = \n",
    "\n",
    "#for i in range(len(lst_tpr)):\n",
    " #   lst_precision[i] = lst_tpr[i]/(lst_tpr[i] + lst_fpr[i])\n",
    "    \n",
    "#print(lst_precision)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df_FINAL_copy = df_FINAL.copy()\n",
    "\n",
    "threshold = 4\n",
    "for i in range(len(df_FINAL_copy)):\n",
    "    if df_FINAL_copy.loc[i, 'ngbr_ratio'] >= threshold:\n",
    "        df_FINAL_copy.loc[i, 'prediction'] = 1\n",
    "    else:\n",
    "        df_FINAL_copy.loc[i, 'prediction'] = 0\n",
    "\n",
    "tp = len(df_FINAL_copy.query(\"prediction==1 and reality==1\").values)\n",
    "fp = len(df_FINAL_copy.query(\"prediction==1 and reality==0\").values)\n",
    "tn = len(df_FINAL_copy.query(\"prediction==0 and reality==0\").values)\n",
    "fn = len(df_FINAL_copy.query(\"prediction==0 and reality==1\").values)\n",
    "\n",
    "p_precise = tp / (tp + fp)\n",
    "p_recall = tp / (tp + fn)\n",
    "\n",
    "print(p_precise)\n",
    "print(p_recall)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#u1=df_FINAL_copy.query(\"(prediction>0 or reality>0) and n_new_edge>0\")\n",
    "#u1=df_FINAL_copy.query(\"user=='AR15V2ULA2EYM' and (prediction>0 or reality>0) and n_new_edge>0 \").sort_values(by='ngbr_ratio', ascending=False)\n",
    "#u1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTES\n",
    "'''\n",
    "Model1: \n",
    "n_movies = 40000 .. n_movies_v = 12000 .. n_test_users = 100 walk_steps = 40 .. top_neighbor = 50 >> AUC = 80.23\n",
    "Model2: \n",
    "n_movies = 40000 .. n_movies_v = 12000 .. n_test_users = 100 walk_steps = 40 .. top_neighbor = 50 >> AUC = 86.89 .. 71.15 .. \n",
    "Model3: \n",
    "n_movies = 40000 .. n_movies_v = 12000 .. n_test_users = 100 walk_steps = 40 .. top_neighbor = 50 >> AUC = \n",
    "Model4: \n",
    "n_movies = 40000 .. n_movies_v = 12000 .. n_test_users = 100 walk_steps = 40 .. top_neighbor = 50 >> AUC = \n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Amazon_movies.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
